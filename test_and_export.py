#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
export_ply.py - å¯¼å‡ºæ¨¡å‹é¢„æµ‹ç»“æœä¸ºPLYç‚¹äº‘æ–‡ä»¶

åŠŸèƒ½:
- åŠ è½½æ¨¡å‹å¹¶å¯¹æµ‹è¯•é›†è¿›è¡Œæ¨ç†
- å¯¼å‡ºåŸå§‹ç‚¹äº‘ã€Ground Truthã€é¢„æµ‹ç»“æœä¸ºPLYæ ¼å¼
- æ”¯æŒCloudCompareç­‰å·¥å…·ç›´æ¥æŸ¥çœ‹

æ•°æ®æ ¼å¼è¯´æ˜:
    HOPSæ•°æ®é›†è¿”å›çš„batchå­—å…¸åŒ…å«ä»¥ä¸‹é”®:
    - positions   : (N, 3) Float32 - ç‚¹äº‘åæ ‡ (ä¸»é”®)
    - colors      : (N, 3) Float32 - RGBé¢œè‰²å€¼ [0-255]
    - semantic    : (N, 1) Float64 - è¯­ä¹‰æ ‡ç­¾ [0-5]
    - semantic_h  : (N, 1) Float64 - å±‚æ¬¡åŒ–è¯­ä¹‰æ ‡ç­¾ [0-1]
    - instance    : (N, 1) Float64 - å®ä¾‹æ ‡ç­¾
    - instance_h  : (N, 1) Float64 - æ ‘æœ¨å®ä¾‹æ ‡ç­¾
    
    æ¨¡å‹é¢„æµ‹è¾“å‡º:
    - output_sem  : TensorField - è¯­ä¹‰åˆ†å‰²logits (N, 6)
    - offsets1    : TensorField - å®ä¾‹åç§»å‘é‡ (N, D)
    - offsets2    : TensorField - æ ‘æœ¨åç§»å‘é‡ (N, D)
    
    ä½¿ç”¨ TensorField.features_at(batch_id) è·å–å…·ä½“ç‰¹å¾

ç”¨æ³•:
    # å¯¼å‡ºå•ä¸ªæ ·æœ¬
    python export_ply.py -w checkpoints/best-mpq.ckpt -i 0
    
    # å¯¼å‡ºå¤šä¸ªæ ·æœ¬
    python export_ply.py -w checkpoints/best-mpq.ckpt -i 0 1 2 3 4
    
    # æŒ‡å®šè¾“å‡ºç›®å½•
    python export_ply.py -w checkpoints/best-mpq.ckpt -i 0 -o ply_results/
    
    # æ‰¹é‡å¯¼å‡ºæ‰€æœ‰æµ‹è¯•é›†
    python export_ply.py -w checkpoints/best-mpq.ckpt --all -n 10
"""

import click
import os
import sys
import torch
import numpy as np
import yaml
from pathlib import Path
from tqdm import tqdm

sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

from models.hapt3d_ours import HAPT3D
from datasets.dataset import HAPT3DDataset
from utils.func import TensorField
import MinkowskiEngine as ME

device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
torch.set_float32_matmul_precision('medium')


# ============================================================================
# PLYå¯¼å‡ºå‡½æ•°
# ============================================================================

def save_ply_with_all_fields(data_dict, output_path):
    """
    ä¿å­˜ç‚¹äº‘ä¸ºPLYæ ¼å¼ï¼ŒåŒ…å«æ‰€æœ‰å­—æ®µä½œä¸ºvertex properties
    
    Args:
        data_dict: æ•°æ®å­—å…¸ï¼ŒåŒ…å«ä»¥ä¸‹é”®:
            - positions   : (N, 3) ç‚¹äº‘åæ ‡
            - colors      : (N, 3) RGBé¢œè‰²
            - semantic    : (N,) æˆ– (N, 1) è¯­ä¹‰æ ‡ç­¾
            - semantic_h  : (N,) æˆ– (N, 1) å±‚æ¬¡åŒ–è¯­ä¹‰æ ‡ç­¾
            - instance    : (N,) æˆ– (N, 1) å®ä¾‹æ ‡ç­¾
            - instance_h  : (N,) æˆ– (N, 1) æ ‘æœ¨å®ä¾‹æ ‡ç­¾
        output_path: è¾“å‡ºPLYæ–‡ä»¶è·¯å¾„
    """
    from plyfile import PlyData, PlyElement
    
    # æå–æ•°æ®
    positions = data_dict['positions']
    colors = data_dict['colors']
    semantic = data_dict['semantic'].squeeze() if data_dict['semantic'].ndim > 1 else data_dict['semantic']
    semantic_h = data_dict['semantic_h'].squeeze() if data_dict['semantic_h'].ndim > 1 else data_dict['semantic_h']
    instance = data_dict['instance'].squeeze() if data_dict['instance'].ndim > 1 else data_dict['instance']
    instance_h = data_dict['instance_h'].squeeze() if data_dict['instance_h'].ndim > 1 else data_dict['instance_h']
    
    # å½’ä¸€åŒ–é¢œè‰²åˆ°[0, 255]
    if colors.max() <= 1.0:
        colors = (colors * 255).astype(np.uint8)
    else:
        colors = colors.astype(np.uint8)
    
    # æ„é€ vertexæ•°æ®ï¼ˆä½¿ç”¨numpy structured arrayï¼‰
    n_points = len(positions)
    vertex_data = np.zeros(
        n_points,
        dtype=[
            ('x', 'f4'), ('y', 'f4'), ('z', 'f4'),           # positions
            ('red', 'u1'), ('green', 'u1'), ('blue', 'u1'),  # colors
            ('semantic', 'i4'),                               # semantic
            ('semantic_h', 'i4'),                             # semantic_h
            ('instance', 'i4'),                               # instance
            ('instance_h', 'i4'),                             # instance_h
        ]
    )
    
    # å¡«å……æ•°æ®
    vertex_data['x'] = positions[:, 0]
    vertex_data['y'] = positions[:, 1]
    vertex_data['z'] = positions[:, 2]
    vertex_data['red'] = colors[:, 0]
    vertex_data['green'] = colors[:, 1]
    vertex_data['blue'] = colors[:, 2]
    vertex_data['semantic'] = semantic.astype(np.int32)
    vertex_data['semantic_h'] = semantic_h.astype(np.int32)
    vertex_data['instance'] = instance.astype(np.int32)
    vertex_data['instance_h'] = instance_h.astype(np.int32)
    
    # åˆ›å»ºPLYå…ƒç´ 
    vertex_element = PlyElement.describe(vertex_data, 'vertex')
    
    # ä¿å­˜PLYæ–‡ä»¶
    ply_data = PlyData([vertex_element], text=False)
    ply_data.write(str(output_path))
    
    print(f"  âœ“ {output_path.name} (å«6ä¸ªæ ‡é‡åœº)")


def colorize_semantic(labels):
    """
    æ ¹æ®è¯­ä¹‰æ ‡ç­¾ç”Ÿæˆé¢œè‰²
    
    Args:
        labels: [N] è¯­ä¹‰æ ‡ç­¾
    
    Returns:
        colors: [N, 3] RGBé¢œè‰²
    """
    SEMANTIC_COLORS = {
        0: [0.0, 0.0, 0.0],        # void
        1: [0.82, 0.71, 0.55],     # ground
        2: [0.18, 0.55, 0.34],     # plant
        3: [1.0, 0.27, 0.0],       # fruit
        4: [0.55, 0.27, 0.07],     # trunk
        5: [0.44, 0.5, 0.56],      # pole
    }
    
    colors = np.zeros((len(labels), 3))
    for i, label in enumerate(labels):
        colors[i] = SEMANTIC_COLORS.get(int(label), [0.5, 0.5, 0.5])
    
    return colors


def colorize_instance(instances):
    """
    æ ¹æ®å®ä¾‹IDç”Ÿæˆç‹¬ç‰¹é¢œè‰²
    
    Args:
        instances: [N] å®ä¾‹ID
    
    Returns:
        colors: [N, 3] RGBé¢œè‰²
    """
    import distinctipy
    
    unique_instances, inverse, counts = np.unique(
        instances, return_inverse=True, return_counts=True
    )
    
    n_instances = len(unique_instances)
    colors_list = distinctipy.get_colors(
        n_instances,
        exclude_colors=[(c, c, c) for c in np.arange(0, 1.01, 0.01)]
    )
    
    # æœ€å¤§å®ä¾‹ï¼ˆèƒŒæ™¯ï¼‰ç”¨ç°è‰²
    bg_idx = np.argmax(counts)
    colors_list[bg_idx] = (0.7, 0.7, 0.7)
    
    colors = np.array([colors_list[idx] for idx in inverse])
    
    return colors


# ============================================================================
# æ¨¡å‹æ¨ç†
# ============================================================================

def model_inference(model, sample, voxel_resolution, device):
    """
    æ¨¡å‹æ¨ç†ï¼Œè¿”å›ä¸Ground Truthæ ¼å¼ä¸€è‡´çš„é¢„æµ‹å­—å…¸
    
    Args:
        model: HAPT3Dæ¨¡å‹
        sample: æ•°æ®é›†æ ·æœ¬ï¼ˆGTæ ¼å¼ï¼‰
        voxel_resolution: ä½“ç´ åˆ†è¾¨ç‡
        device: è®¾å¤‡
    
    Returns:
        predictions: é¢„æµ‹å­—å…¸ï¼Œæ ¼å¼ä¸GTä¸€è‡´
            - positions   : (N, 3) Float32
            - colors      : (N, 3) Float32
            - semantic    : (N, 1) Float64
            - semantic_h  : (N, 1) Float64
            - instance    : (N, 1) Float64
            - instance_h  : (N, 1) Float64
    """
    model.eval()
    
    # ==================== æ•°æ®å‡†å¤‡ ====================
    if 'positions' in sample:
        points_data = sample['positions']
    elif 'points' in sample:
        points_data = sample['points']
    else:
        raise KeyError("æ•°æ®ä¸­æ—¢æ²¡æœ‰ 'positions' ä¹Ÿæ²¡æœ‰ 'points' é”®")
    
    colors_data = sample['colors']
    
    # è½¬æ¢ä¸ºtensorå¹¶ç§»åˆ°GPU
    if isinstance(points_data, np.ndarray):
        points_data = torch.from_numpy(points_data).float()
    if isinstance(colors_data, np.ndarray):
        colors_data = torch.from_numpy(colors_data).float()
    
    # TensorFieldå†…éƒ¨ä½¿ç”¨numpyï¼Œéœ€è¦ä¿æŒåœ¨CPUä¸Šåˆ›å»º
    points_data = points_data.float()
    colors_data = colors_data.float()
    
    # ==================== åˆ›å»ºTensorField ====================
    tensorfield = {
        "points": [points_data],
        "feats": [colors_data]
    }
    dense_input = TensorField(tensorfield, voxel_resolution=voxel_resolution)
    
    # ==================== æ¨¡å‹å‰å‘ä¼ æ’­ ====================
    # æ¨¡å‹çš„forwardæ–¹æ³•ä¼šè‡ªåŠ¨å¤„ç†è®¾å¤‡è½¬æ¢ï¼ˆé€šè¿‡.sparse()å’Œmodelå†…éƒ¨ï¼‰
    with torch.no_grad():
        output_sem, offsets1, offsets2 = model(dense_input)
    
    # ==================== æå–é¢„æµ‹ç»“æœ ====================
    # è¯­ä¹‰é¢„æµ‹ - (N, n_classes) -> (N,)
    sem_pred_logits = output_sem.features_at(0)  # (N, 6)
    sem_pred = torch.argmax(sem_pred_logits, dim=1)  # (N,)
    
    # å±‚æ¬¡åŒ–è¯­ä¹‰é¢„æµ‹ - 0: background, 1: tree (fruit + trunk)
    sem_h_pred = torch.zeros_like(sem_pred)
    sem_h_pred[torch.logical_or(sem_pred == 3, sem_pred == 4)] = 1  # fruit=3, trunk=4
    
    # åç§»å‘é‡
    offsets_ins = offsets1.features_at(0)  # (N, D)
    offsets_tree = offsets2.features_at(0)  # (N, D)
    offset_ins_xyz = offsets_ins[:, :3] if offsets_ins.shape[1] >= 3 else offsets_ins
    offset_tree_xyz = offsets_tree[:, :3] if offsets_tree.shape[1] >= 3 else offsets_tree
    
    # ==================== HDBSCANèšç±»å¾—åˆ°å®ä¾‹é¢„æµ‹ ====================
    from hdbscan import HDBSCAN
    
    coords = dense_input.coordinates_at(0) * voxel_resolution  # æ¢å¤åŸå§‹åæ ‡
    
    # å®ä¾‹èšç±»ï¼ˆfruit + trunkï¼‰
    centers_ins = (coords + offset_ins_xyz).cpu().numpy()
    clusterer_ins = HDBSCAN(min_cluster_size=50, min_samples=10)
    ins_pred = clusterer_ins.fit_predict(centers_ins)
    ins_pred = torch.from_numpy(ins_pred).long().to(device)
    
    # æ ‘æœ¨èšç±»ï¼ˆhierarchy levelï¼‰
    centers_tree = (coords + offset_tree_xyz).cpu().numpy()
    clusterer_tree = HDBSCAN(min_cluster_size=200, min_samples=20)
    ins_h_pred = clusterer_tree.fit_predict(centers_tree)
    ins_h_pred = torch.from_numpy(ins_h_pred).long().to(device)
    
    # ==================== æ•´ç†æˆGTæ ¼å¼çš„å­—å…¸ ====================
    predictions = {
        # åæ ‡å’Œé¢œè‰²ï¼ˆä¸GTç›¸åŒï¼‰
        'positions': points_data.cpu().float(),           # (N, 3) Float32
        'colors': colors_data.cpu().float(),              # (N, 3) Float32
        
        # è¯­ä¹‰é¢„æµ‹ï¼ˆè½¬æ¢ä¸ºFloat64ä»¥åŒ¹é…GTæ ¼å¼ï¼‰
        'semantic': sem_pred.cpu().unsqueeze(1).double(), # (N, 1) Float64
        'semantic_h': sem_h_pred.cpu().unsqueeze(1).double(),  # (N, 1) Float64
        
        # å®ä¾‹é¢„æµ‹ï¼ˆè½¬æ¢ä¸ºFloat64ä»¥åŒ¹é…GTæ ¼å¼ï¼‰
        'instance': ins_pred.cpu().unsqueeze(1).double(), # (N, 1) Float64
        'instance_h': ins_h_pred.cpu().unsqueeze(1).double(),  # (N, 1) Float64
        
        # é¢å¤–ä¿¡æ¯ï¼ˆç”¨äºè°ƒè¯•ï¼‰
        '_offsets_instance': offsets_ins.cpu(),           # (N, D) å®ä¾‹åç§»å‘é‡
        '_offsets_tree': offsets_tree.cpu(),              # (N, D) æ ‘æœ¨åç§»å‘é‡
        '_logits': sem_pred_logits.cpu(),                 # (N, 6) è¯­ä¹‰logits
    }
    
    return predictions


def inference_and_export(model, sample, voxel_resolution, output_dir, sample_idx):
    """
    å¯¹å•ä¸ªæ ·æœ¬è¿›è¡Œæ¨ç†å¹¶å¯¼å‡ºPLYæ–‡ä»¶
    
    Args:
        model: HAPT3Dæ¨¡å‹
        sample: æ•°æ®é›†æ ·æœ¬ï¼ˆGround Truthï¼‰
        voxel_resolution: ä½“ç´ åˆ†è¾¨ç‡
        output_dir: è¾“å‡ºç›®å½•
        sample_idx: æ ·æœ¬ç´¢å¼•
    """
    device = next(model.parameters()).device
    
    # ==================== æ¨¡å‹æ¨ç† ====================
    print(f"\næ ·æœ¬ {sample_idx}:")
    print(f"  æ¨ç†ä¸­...")
    
    # è·å–ä¸GTæ ¼å¼ä¸€è‡´çš„é¢„æµ‹ç»“æœ
    predictions = model_inference(model, sample, voxel_resolution, device)
    
    # ==================== æ‰“å°æ ¼å¼å¯¹æ¯” ====================
    print(f"\n  Ground Truth æ ¼å¼:")
    coords_key = 'positions' if 'positions' in sample else 'points'
    for key in [coords_key, 'colors', 'semantic', 'semantic_h', 'instance', 'instance_h']:
        if key in sample:
            value = sample[key]
            if torch.is_tensor(value):
                print(f"    - {key:12s}: shape={tuple(value.shape)}, dtype={value.dtype}, device={value.device}")
    
    print(f"\n  æ¨¡å‹é¢„æµ‹æ ¼å¼:")
    for key in ['positions', 'colors', 'semantic', 'semantic_h', 'instance', 'instance_h']:
        if key in predictions:
            value = predictions[key]
            print(f"    - {key:12s}: shape={tuple(value.shape)}, dtype={value.dtype}, device={value.device}")
    
    # ==================== æå–æ•°æ®ç”¨äºå¯¼å‡º ====================
    points = predictions['positions'].numpy()
    colors = predictions['colors'].numpy()
    
    # Ground Truth
    sem_gt = sample['semantic'].squeeze().numpy().astype(np.int32)
    ins_gt = sample['instance'].squeeze().numpy().astype(np.int32) if 'instance' in sample else None
    ins_h_gt = sample['instance_h'].squeeze().numpy().astype(np.int32) if 'instance_h' in sample else None
    
    # é¢„æµ‹ç»“æœ
    sem_pred = predictions['semantic'].squeeze().numpy().astype(np.int32)
    sem_h_pred = predictions['semantic_h'].squeeze().numpy().astype(np.int32)
    ins_pred = predictions['instance'].squeeze().numpy().astype(np.int32)
    ins_h_pred = predictions['instance_h'].squeeze().numpy().astype(np.int32)
    
    # ==================== å¯¼å‡ºPLYæ–‡ä»¶ ====================
    
    # ==================== å¯¼å‡ºPLYæ–‡ä»¶ ====================
    # åˆ›å»ºè¾“å‡ºç›®å½•
    sample_dir = output_dir / f"sample_{sample_idx:03d}"
    sample_dir.mkdir(parents=True, exist_ok=True)
    
    print(f"  ç‚¹æ•°: {len(points)}")
    print(f"  è¾“å‡ºç›®å½•: {sample_dir}")
    
    # å‡†å¤‡Ground Truthå­—å…¸
    gt_dict = {
        'positions': points,
        'colors': colors,
        'semantic': sem_gt,
        'semantic_h': sample['semantic_h'].squeeze().numpy().astype(np.int32),
        'instance': ins_gt if ins_gt is not None else np.zeros_like(sem_gt),
        'instance_h': ins_h_gt if ins_h_gt is not None else np.zeros_like(sem_gt),
    }
    
    # å‡†å¤‡é¢„æµ‹å­—å…¸
    pred_dict = {
        'positions': points,
        'colors': colors,
        'semantic': sem_pred,
        'semantic_h': sem_h_pred,
        'instance': ins_pred,
        'instance_h': ins_h_pred,
    }
    
    # ä¿å­˜Ground Truth PLYï¼ˆåŒ…å«æ‰€æœ‰å­—æ®µï¼‰
    save_ply_with_all_fields(
        gt_dict,
        sample_dir / "ground_truth.ply"
    )
    
    # ä¿å­˜é¢„æµ‹ç»“æœPLYï¼ˆåŒ…å«æ‰€æœ‰å­—æ®µï¼‰
    save_ply_with_all_fields(
        pred_dict,
        sample_dir / "predictions.ply"
    )
    
    # ==================== ä¿å­˜é¢å¤–è°ƒè¯•ä¿¡æ¯ï¼ˆNPZæ ¼å¼ï¼‰====================
    # ä¿å­˜åç§»å‘é‡å’Œlogitsç”¨äºè°ƒè¯•
    debug_path = sample_dir / "debug_info.npz"
    np.savez(
        debug_path,
        offsets_instance=predictions['_offsets_instance'].numpy(),
        offsets_tree=predictions['_offsets_tree'].numpy(),
        logits=predictions['_logits'].numpy(),
    )
    print(f"  âœ“ è°ƒè¯•ä¿¡æ¯å·²ä¿å­˜: debug_info.npz")
    
    # ==================== è®¡ç®—ç»Ÿè®¡ä¿¡æ¯ ====================
    
    # ==================== è®¡ç®—ç»Ÿè®¡ä¿¡æ¯ ====================
    stats = {
        'sample_idx': sample_idx,
        'num_points': len(points),
        'semantic_accuracy': np.mean(sem_pred == sem_gt) * 100,
        'num_instances_pred': len(np.unique(ins_pred)),
        'num_trees_pred': len(np.unique(ins_h_pred)),
    }
    
    if ins_gt is not None:
        stats['num_instances_gt'] = len(np.unique(ins_gt))
    if ins_h_gt is not None:
        stats['num_trees_gt'] = len(np.unique(ins_h_gt))
    
    # ä¿å­˜ç»Ÿè®¡ä¿¡æ¯
    stats_path = sample_dir / "stats.txt"
    with open(stats_path, 'w') as f:
        for key, value in stats.items():
            f.write(f"{key}: {value}\n")
    
    return stats


# ============================================================================
# ä¸»å‡½æ•°
# ============================================================================

@click.command()
@click.option('--weights', '-w', type=str, required=True,
              help='æ¨¡å‹æƒé‡è·¯å¾„ (.ckpt)')
@click.option('--config', '-c', type=str, default=None,
              help='é…ç½®æ–‡ä»¶è·¯å¾„ (.yaml)')
@click.option('--data_path', '-d', type=str, default=None,
              help='æ•°æ®é›†è·¯å¾„')
@click.option('--indices', '-i', multiple=True, type=int,
              help='è¦å¯¼å‡ºçš„æ ·æœ¬ç´¢å¼•ï¼ˆå¯æŒ‡å®šå¤šä¸ªï¼‰')
@click.option('--split', type=str, default='val',
              help='æ•°æ®é›†åˆ’åˆ†: train/val/test')
@click.option('--output', '-o', type=str, default='ply_exports/',
              help='è¾“å‡ºç›®å½•')
@click.option('--all', 'export_all', is_flag=True, default=False,
              help='å¯¼å‡ºæ‰€æœ‰æ ·æœ¬')
@click.option('--num_samples', '-n', type=int, default=None,
              help='å¯¼å‡ºæ ·æœ¬æ•°é‡ï¼ˆä¸--allä¸€èµ·ä½¿ç”¨ï¼‰')
def main(weights, config, data_path, indices, split, output, export_all, num_samples):
    """
    HAPT3D æ¨¡å‹é¢„æµ‹ç»“æœPLYå¯¼å‡ºå·¥å…·
    
    å¯¼å‡ºçš„æ–‡ä»¶å¯ä»¥åœ¨CloudCompareä¸­æ‰“å¼€æŸ¥çœ‹
    """
    print("\n" + "="*70)
    print("HAPT3D PLYç‚¹äº‘å¯¼å‡ºå·¥å…·")
    print("="*70 + "\n")
    
    # åŠ è½½é…ç½®
    print("ğŸ“‹ åŠ è½½é…ç½®...")
    ckpt = torch.load(weights, map_location='cpu')
    if 'hyper_parameters' in ckpt:
        cfg = ckpt['hyper_parameters']
    elif config:
        cfg = yaml.safe_load(open(config))
    else:
        raise ValueError("æ— æ³•ä»checkpointåŠ è½½é…ç½®ï¼Œè¯·ä½¿ç”¨ --config æŒ‡å®šé…ç½®æ–‡ä»¶")
    
    if data_path:
        if 'data' in cfg:
            cfg['data']['path'] = data_path
        else:
            cfg['data_path'] = data_path
    
    print(f"  å®éªŒID: {cfg['experiment']['id']}")
    print(f"  ä½“ç´ åˆ†è¾¨ç‡: {cfg['train']['voxel_resolution']}")
    
    # åŠ è½½æ¨¡å‹
    print("\nğŸ¤– åŠ è½½æ¨¡å‹...")
    model = HAPT3D.load_from_checkpoint(weights, cfg=cfg, viz=False)
    model = model.to(device)
    model.eval()
    print(f"  æ¨¡å‹å·²åŠ è½½åˆ°: {device}")
    
    # åŠ è½½æ•°æ®é›†
    print(f"\nğŸ“¦ åŠ è½½æ•°æ®é›† ({split})...")
    data_path_value = cfg.get('data', {}).get('path', cfg.get('data_path', 'data/hopt3d'))
    dataset = HAPT3DDataset(
        data_path=data_path_value,
        config=cfg,
        split=split,
        overfit=False
    )
    print(f"  æ•°æ®é›†å¤§å°: {len(dataset)}")
    
    # ç¡®å®šè¦å¯¼å‡ºçš„æ ·æœ¬
    if export_all:
        if num_samples:
            indices = range(min(num_samples, len(dataset)))
        else:
            indices = range(len(dataset))
    elif not indices:
        indices = [0]  # é»˜è®¤å¯¼å‡ºç¬¬ä¸€ä¸ªæ ·æœ¬
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    output_dir = Path(output)
    output_dir.mkdir(parents=True, exist_ok=True)
    print(f"\nğŸ’¾ è¾“å‡ºç›®å½•: {output_dir}")
    
    # æ‰¹é‡å¯¼å‡º
    print(f"\nğŸ¨ å¼€å§‹å¯¼å‡º (å…± {len(indices)} ä¸ªæ ·æœ¬)...\n")
    
    voxel_resolution = cfg['train']['voxel_resolution']
    all_stats = []
    
    for idx in tqdm(indices, desc="å¯¼å‡ºPLY"):
        if idx >= len(dataset):
            print(f"âš ï¸  è­¦å‘Š: ç´¢å¼• {idx} è¶…å‡ºæ•°æ®é›†èŒƒå›´ï¼Œè·³è¿‡")
            continue
        
        sample = dataset[idx]
        
        try:
            stats = inference_and_export(
                model, sample, voxel_resolution, output_dir, idx
            )
            all_stats.append(stats)
        except Exception as e:
            print(f"âŒ æ ·æœ¬ {idx} å¯¼å‡ºå¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
    
    # ä¿å­˜æ€»ä½“ç»Ÿè®¡ä¿¡æ¯
    if all_stats:
        summary_path = output_dir / "summary.txt"
        with open(summary_path, 'w') as f:
            f.write("=" * 70 + "\n")
            f.write("HAPT3D PLYå¯¼å‡ºæ€»ç»“\n")
            f.write("=" * 70 + "\n\n")
            f.write(f"å¯¼å‡ºæ ·æœ¬æ•°: {len(all_stats)}\n")
            f.write(f"æ•°æ®é›†åˆ’åˆ†: {split}\n")
            f.write(f"æ¨¡å‹æƒé‡: {weights}\n\n")
            
            avg_acc = np.mean([s['semantic_accuracy'] for s in all_stats])
            f.write(f"å¹³å‡è¯­ä¹‰å‡†ç¡®ç‡: {avg_acc:.2f}%\n\n")
            
            f.write("å„æ ·æœ¬è¯¦æƒ…:\n")
            f.write("-" * 70 + "\n")
            for stats in all_stats:
                f.write(f"æ ·æœ¬ {stats['sample_idx']:3d}: "
                       f"ç‚¹æ•°={stats['num_points']:6d}, "
                       f"å‡†ç¡®ç‡={stats['semantic_accuracy']:.2f}%\n")
        
        print(f"\nâœ“ æ€»ç»“ä¿å­˜è‡³: {summary_path}")
    
    print("\n" + "="*70)
    print("âœ… å¯¼å‡ºå®Œæˆï¼")
    print("="*70)
    print(f"\nğŸ“ è¾“å‡ºç›®å½•: {output_dir}")
    print("\nğŸ’¡ ä½¿ç”¨CloudCompareæ‰“å¼€PLYæ–‡ä»¶:")
    print(f"   cloudcompare.CloudCompare {output_dir}/sample_000/ground_truth.ply")
    print(f"   cloudcompare.CloudCompare {output_dir}/sample_000/predictions.ply")
    print("\næ–‡ä»¶è¯´æ˜:")
    print("  ground_truth.ply  - Ground Truthï¼ˆåŒ…å«æ‰€æœ‰æ ‡é‡åœºï¼‰")
    print("  predictions.ply   - æ¨¡å‹é¢„æµ‹ï¼ˆåŒ…å«æ‰€æœ‰æ ‡é‡åœºï¼‰")
    print("  debug_info.npz    - è°ƒè¯•ä¿¡æ¯ï¼ˆåç§»å‘é‡ã€logitsï¼‰")
    print("\næ ‡é‡åœºï¼ˆScalar Fieldsï¼‰:")
    print("  - positions   : (x, y, z) ç‚¹äº‘åæ ‡")
    print("  - colors      : (red, green, blue) RGBé¢œè‰²")
    print("  - semantic    : è¯­ä¹‰æ ‡ç­¾ [0-5]")
    print("  - semantic_h  : å±‚æ¬¡åŒ–è¯­ä¹‰æ ‡ç­¾ [0-1]")
    print("  - instance    : å®ä¾‹æ ‡ç­¾")
    print("  - instance_h  : æ ‘æœ¨å®ä¾‹æ ‡ç­¾")
    print()


if __name__ == "__main__":
    main()
