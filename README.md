# HAPT3D é¡¹ç›®ä»£ç è¯¦è§£

## ğŸ“ é¡¹ç›®ç»“æ„æ¦‚è§ˆ

```
hapt3D/
â”œâ”€â”€ train.py                 # è®­ç»ƒå…¥å£è„šæœ¬
â”œâ”€â”€ test.py                  # æµ‹è¯•å…¥å£è„šæœ¬
â”œâ”€â”€ requirements.txt         # ä¾èµ–åŒ…åˆ—è¡¨
â”œâ”€â”€ INSTALL.md              # å®‰è£…æŒ‡å—
â”œâ”€â”€ Dockerfile              # Dockeré…ç½®
â”œâ”€â”€ Makefile                # æ„å»ºè„šæœ¬
â”œâ”€â”€ config/                 # é…ç½®æ–‡ä»¶ç›®å½•
â”‚   â”œâ”€â”€ config.yaml         # é»˜è®¤é…ç½®
â”‚   â”œâ”€â”€ config_full.yaml    # å®Œæ•´è·³è·ƒè¿æ¥é…ç½®ï¼ˆè®ºæ–‡æ–¹æ³•ï¼‰
â”‚   â”œâ”€â”€ config_standard.yaml # æ ‡å‡†è·³è·ƒè¿æ¥é…ç½®
â”‚   â”œâ”€â”€ config_no_skip.yaml  # æ— è·³è·ƒè¿æ¥é…ç½®
â”‚   â””â”€â”€ config_dec_skip.yaml # ä»…è§£ç å™¨è·³è·ƒè¿æ¥é…ç½®
â”œâ”€â”€ datasets/               # æ•°æ®é›†å¤„ç†æ¨¡å—
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ dataloader.py       # PyTorch Lightning DataModule
â”‚   â”œâ”€â”€ dataset.py          # æ•°æ®é›†ç±»å®šä¹‰
â”‚   â””â”€â”€ tf.py               # æ•°æ®å¢å¼ºå˜æ¢
â”œâ”€â”€ models/                 # æ¨¡å‹å®šä¹‰æ¨¡å—
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ hapt3d.py           # ä¸»æ¨¡å‹ï¼ˆLightningModuleï¼‰
â”‚   â”œâ”€â”€ minkunet.py         # æ ‡å‡†MinkUNet
â”‚   â”œâ”€â”€ minkunet_full.py    # å®Œæ•´è·³è·ƒè¿æ¥MinkUNetï¼ˆè®ºæ–‡æ ¸å¿ƒï¼‰
â”‚   â”œâ”€â”€ minkunet_no_skip.py # æ— è·³è·ƒè¿æ¥MinkUNet
â”‚   â”œâ”€â”€ minkunet_decoder_only.py # ä»…è§£ç å™¨è·³è·ƒè¿æ¥
â”‚   â””â”€â”€ resnet.py           # ResNetåŸºç¡€æ¨¡å—
â””â”€â”€ utils/                  # å·¥å…·å‡½æ•°æ¨¡å—
    â”œâ”€â”€ __init__.py
    â”œâ”€â”€ evaluation.py       # è¯„ä¼°æŒ‡æ ‡è®¡ç®—
    â”œâ”€â”€ func.py             # è¾…åŠ©å‡½æ•°
    â”œâ”€â”€ lovasz.py           # LovÃ¡szæŸå¤±å‡½æ•°
    â””â”€â”€ viz.py              # å¯è§†åŒ–å·¥å…·
```

---

## ğŸ”§ ç¯å¢ƒé…ç½®ä¸å®‰è£…

### ä¾èµ–ç¯å¢ƒ

```bash
# åˆ›å»ºcondaè™šæ‹Ÿç¯å¢ƒ
conda create --name hapt3d python=3.9
conda activate hapt3d

# å®‰è£…PyTorchï¼ˆCUDA 11.3ç‰ˆæœ¬ï¼‰
pip install torch==1.12.1+cu113 --extra-index-url https://download.pytorch.org/whl/cu113 --no-cache-dir

# å®‰è£…NumPyå’Œsetuptools
pip install numpy==1.24.2
pip install setuptools==60.0

# å®‰è£…PyKeOpsï¼ˆé«˜æ•ˆGPUè®¡ç®—ï¼‰
pip install pykeops --no-cache-dir

# å®‰è£…MinkowskiEngineï¼ˆç¨€ç–3Då·ç§¯åº“ï¼‰- æ ¸å¿ƒä¾èµ–
pip3 install -U git+https://github.com/NVIDIA/MinkowskiEngine -v --no-deps

# å®‰è£…PyTorch Lightningï¼ˆè®­ç»ƒæ¡†æ¶ï¼‰
pip install pytorch-lightning==1.9.0 --no-deps
pip install fsspec lightning-utilities

# å®‰è£…å…¶ä»–ä¾èµ–
pip install tqdm pyyaml torchmetrics==1.4.1 ipdb
pip install open3d tensorboard hdbscan distinctipy
pip install optuna==3.6.1 optuna-integration
```

### æ ¸å¿ƒä¾èµ–è¯´æ˜

| ä¾èµ–åº“ | ç‰ˆæœ¬ | ä½œç”¨ |
|--------|------|------|
| **MinkowskiEngine** | æœ€æ–° | ç¨€ç–3Då·ç§¯æ ¸å¿ƒåº“ï¼Œå¤„ç†ç‚¹äº‘çš„ç¨€ç–å¼ é‡è¡¨ç¤º |
| **PyTorch Lightning** | 1.9.0 | è®­ç»ƒæ¡†æ¶ï¼Œç®€åŒ–è®­ç»ƒ/éªŒè¯/æµ‹è¯•æµç¨‹ |
| **Open3D** | - | ç‚¹äº‘I/Oå’Œå¤„ç† |
| **HDBSCAN** | - | å±‚æ¬¡èšç±»ï¼Œç”¨äºå®ä¾‹åˆ†å‰²åå¤„ç† |
| **torchmetrics** | 1.4.1 | è¯„ä¼°æŒ‡æ ‡è®¡ç®—ï¼ˆIoU, PQç­‰ï¼‰ |

---

## âš™ï¸ é…ç½®æ–‡ä»¶è¯¦è§£

é…ç½®æ–‡ä»¶ä½äº `config/` ç›®å½•ï¼Œä½¿ç”¨YAMLæ ¼å¼ã€‚ä»¥ `config_full.yaml` ä¸ºä¾‹ï¼š

```yaml
experiment:
  id: "full_1"              # å®éªŒæ ‡è¯†ç¬¦ï¼Œç”¨äºåŒºåˆ†ä¸åŒå®éªŒ

data_path: "data/hopt3d"    # æ•°æ®é›†è·¯å¾„

network:
  tanh: True                # æ˜¯å¦å¯¹åç§»è¾“å‡ºä½¿ç”¨tanhæ¿€æ´»ï¼ˆå½’ä¸€åŒ–åˆ°[-1,1]ï¼‰
  embeddings_only: False    # æ˜¯å¦åªè¾“å‡ºåµŒå…¥å‘é‡
  skip: "full"              # è·³è·ƒè¿æ¥ç±»å‹: "standard", "no_skip", "decoder_only", "full"
  name: "MinkUNet14A"       # ç½‘ç»œæ¶æ„åç§°

tasks:
  semantic_segmentation:
    n_classes: 6            # è¯­ä¹‰ç±»åˆ«æ•°ï¼š0-void, 1-ground, 2-plant, 3-fruit, 4-trunk, 5-pole

train:
  ignore_idx: 0             # å¿½ç•¥çš„æ ‡ç­¾ç´¢å¼•ï¼ˆvoidç±»åˆ«ï¼‰
  max_epoch: 450            # æœ€å¤§è®­ç»ƒè½®æ•°
  lr: 0.005                 # å­¦ä¹ ç‡
  batch_size: 1             # æ‰¹æ¬¡å¤§å°ï¼ˆç‚¹äº‘é€šå¸¸è®¾ä¸º1ï¼‰
  n_gpus: 1                 # GPUæ•°é‡
  workers: 0                # æ•°æ®åŠ è½½çº¿ç¨‹æ•°
  overfit: False            # æ˜¯å¦è¿‡æ‹Ÿåˆæ¨¡å¼ï¼ˆç”¨äºè°ƒè¯•ï¼‰
  voxel_resolution: 0.003   # ä½“ç´ åˆ†è¾¨ç‡ï¼ˆ3mmï¼‰ï¼Œå½±å“ç‚¹äº‘ç¨€ç–åŒ–ç¨‹åº¦

transform:                  # æ•°æ®å¢å¼ºå‚æ•°
  min_scalefactor: 0.8      # æœ€å°ç¼©æ”¾å› å­
  max_scalefactor: 1.2      # æœ€å¤§ç¼©æ”¾å› å­
  max_rotation_angle_degree_x: 15   # Xè½´æœ€å¤§æ—‹è½¬è§’åº¦
  max_rotation_angle_degree_y: 15   # Yè½´æœ€å¤§æ—‹è½¬è§’åº¦
  max_rotation_angle_degree_z: 180  # Zè½´æœ€å¤§æ—‹è½¬è§’åº¦
  max_shear: 0.2            # æœ€å¤§å‰ªåˆ‡å˜æ¢
  min_downsample: 0.6       # æœ€å°ä¸‹é‡‡æ ·æ¯”ä¾‹
  max_downsample: 1.0       # æœ€å¤§ä¸‹é‡‡æ ·æ¯”ä¾‹
  # é¢œè‰²å¢å¼ºå‚æ•°
  min_contrast: 0.8
  max_contrast: 1.2
  max_brightness: 0.2
  max_hue: 0.15
  max_saturation: 0.15

val:
  min_n_points_fruit: 60    # æœå®å®ä¾‹æœ€å°ç‚¹æ•°é˜ˆå€¼
  min_n_points_trunk: 250   # æ ‘å¹²å®ä¾‹æœ€å°ç‚¹æ•°é˜ˆå€¼
  min_n_points_tree: 1000   # æ ‘æœ¨å®ä¾‹æœ€å°ç‚¹æ•°é˜ˆå€¼
  pq_from_epoch: 50         # ä»ç¬¬50è½®å¼€å§‹è®¡ç®—PQæŒ‡æ ‡

test:
  dump_metrics: True        # æ˜¯å¦ä¿å­˜æµ‹è¯•æŒ‡æ ‡åˆ°JSONæ–‡ä»¶
```

### è·³è·ƒè¿æ¥å˜ä½“å¯¹æ¯”

| é…ç½® | è·³è·ƒè¿æ¥æ–¹å¼ | è¯´æ˜ |
|------|-------------|------|
| `standard` | ç¼–ç å™¨â†’è§£ç å™¨ | ä¼ ç»ŸUNetæ–¹å¼ |
| `no_skip` | æ— è·³è·ƒè¿æ¥ | æ¶ˆèå®éªŒç”¨ |
| `decoder_only` | å‰åºè§£ç å™¨â†’åç»­è§£ç å™¨ | ä»…è§£ç å™¨é—´ä¼ é€’ |
| **`full`** | ç¼–ç å™¨+å‰åºè§£ç å™¨â†’è§£ç å™¨ | **è®ºæ–‡æå‡ºçš„æ–¹æ³•** |

---

## ğŸ—‚ï¸ æ•°æ®é›†æ¨¡å—è¯¦è§£

### 1. æ•°æ®é›†ç±» (`datasets/dataset.py`)

```python
class HAPT3DDataset(Dataset):
    """
    HAPT3Dæ•°æ®é›†ç±»ï¼Œç”¨äºåŠ è½½PLYæ ¼å¼çš„ç‚¹äº‘æ–‡ä»¶
    
    æ•°æ®æ ¼å¼è¦æ±‚:
    - ç‚¹äº‘æ–‡ä»¶: PLYæ ¼å¼
    - åŒ…å«å­—æ®µ: x, y, z (åæ ‡), red, green, blue (é¢œè‰²), 
                semantic, instance, semantic_h, instance_h (æ ‡ç­¾)
    """
```

**æ•°æ®åŠ è½½æµç¨‹:**

1. **è¯»å–PLYæ–‡ä»¶** - ä½¿ç”¨Open3Dè¯»å–ç‚¹äº‘
2. **æå–åæ ‡å’Œé¢œè‰²** - å½’ä¸€åŒ–é¢œè‰²å€¼åˆ°[0,1]
3. **åŠ è½½æ ‡ç­¾** - è¯­ä¹‰/å®ä¾‹æ ‡ç­¾åŠå…¶å±‚æ¬¡ç‰ˆæœ¬
4. **ç‚¹äº‘å½’ä¸€åŒ–** - å°†åæ ‡ä¸­å¿ƒåŒ–å¹¶ç¼©æ”¾
5. **æ•°æ®å¢å¼º** - å‡ ä½•å˜æ¢å’Œé¢œè‰²å¢å¼ºï¼ˆä»…è®­ç»ƒæ—¶ï¼‰

**è¯­ä¹‰ç±»åˆ«å®šä¹‰:**

| ID | ç±»åˆ« | è‹±æ–‡ |
|----|------|------|
| 0 | ç©º | void |
| 1 | åœ°é¢ | ground |
| 2 | æ¤ç‰© | plant |
| 3 | æœå® | fruit |
| 4 | æ ‘å¹² | trunk |
| 5 | æ†æŸ± | pole |

**ç±»åˆ«åˆ’åˆ†:**
- **Stuffç±»åˆ«** (èƒŒæ™¯): ground, plant, pole (IDs: 1, 2, 5)
- **Thingsç±»åˆ«** (å¯æ•°ç‰©ä½“): fruit, trunk (IDs: 3, 4)

### 2. æ•°æ®åŠ è½½å™¨ (`datasets/dataloader.py`)

```python
class HAPT3DDataModule(LightningDataModule):
    """
    PyTorch Lightningæ•°æ®æ¨¡å—
    
    åŠŸèƒ½:
    - åˆ›å»ºè®­ç»ƒ/éªŒè¯/æµ‹è¯•æ•°æ®é›†
    - é…ç½®DataLoaderå‚æ•°
    - ç®¡ç†æ•°æ®å¢å¼ºå¼€å…³
    """
    
    def train_dataloader(self):
        # è®­ç»ƒæ—¶å¯ç”¨æ•°æ®å¢å¼º
        return DataLoader(
            HAPT3DDataset(path, split='train', transform=True, ...),
            batch_size=1,
            collate_fn=lambda x: x[0]  # ç›´æ¥è¿”å›å•ä¸ªæ ·æœ¬
        )
```

### 3. æ•°æ®å¢å¼º (`datasets/tf.py`)

```python
# å‡ ä½•å¢å¼º
def geometricaug(coords, cfg, phase='train'):
    """
    å‡ ä½•æ•°æ®å¢å¼ºï¼ŒåŒ…æ‹¬:
    - éšæœºç¼©æ”¾ (scale)
    - éšæœºæ—‹è½¬ (rotation around x, y, z axes)
    - éšæœºå‰ªåˆ‡ (shear)
    - éšæœºä¸‹é‡‡æ · (downsampling)
    """

# é¢œè‰²å¢å¼º  
def coloraug(colors, cfg, phase='train'):
    """
    é¢œè‰²æ•°æ®å¢å¼ºï¼ŒåŒ…æ‹¬:
    - å¯¹æ¯”åº¦è°ƒæ•´ (contrast)
    - äº®åº¦è°ƒæ•´ (brightness)
    - è‰²è°ƒè°ƒæ•´ (hue)
    - é¥±å’Œåº¦è°ƒæ•´ (saturation)
    """
```

---

## ğŸ§  æ¨¡å‹æ¶æ„è¯¦è§£

### 1. ä¸»æ¨¡å‹ç±» (`models/hapt3d.py`)

```python
class HAPT3D(LightningModule):
    """
    HAPT3Dä¸»æ¨¡å‹ï¼Œç»§æ‰¿è‡ªPyTorch Lightningçš„LightningModule
    
    åŒ…å«:
    - ç½‘ç»œéª¨æ¶ (MinkUNet)
    - æŸå¤±å‡½æ•°è®¡ç®—
    - è®­ç»ƒ/éªŒè¯/æµ‹è¯•æ­¥éª¤
    - åå¤„ç†å’Œè¯„ä¼°
    """
```

**æ¨¡å‹åˆå§‹åŒ–å…³é”®éƒ¨åˆ†:**

```python
def __init__(self, cfg):
    # æ ¹æ®é…ç½®é€‰æ‹©ç½‘ç»œæ¶æ„
    if cfg['network']['skip'] == "standard":
        from models.minkunet import MinkUNet14A as MinkUNet
    elif cfg['network']['skip'] == "full":
        from models.minkunet_full import MinkUNet14A as MinkUNet  # è®ºæ–‡æ–¹æ³•
    elif cfg['network']['skip'] == "no_skip":
        from models.minkunet_no_skip import MinkUNet14A as MinkUNet
    elif cfg['network']['skip'] == "decoder_only":
        from models.minkunet_decoder_only import MinkUNet14A as MinkUNet
    
    # å®ä¾‹åŒ–ç½‘ç»œ
    self.network = MinkUNet(
        in_channels=3,          # è¾“å…¥é€šé“æ•° (RGB)
        out_channels=6,         # è¯­ä¹‰ç±»åˆ«æ•°
        D=3,                    # 3Dç©ºé—´
        embeddings_only=False,
        use_tanh=True
    )
    
    # æŸå¤±å‡½æ•°
    self.ce = nn.CrossEntropyLoss(ignore_index=0)  # è¯­ä¹‰åˆ†å‰²æŸå¤±
    self.lovasz = IoULovaszLoss(invert=False)      # å®ä¾‹åˆ†å‰²æŸå¤±
```

### 2. å‰å‘ä¼ æ’­

```python
def forward(self, data):
    """
    å‰å‘ä¼ æ’­æµç¨‹:
    1. ä½“ç´ åŒ–ç‚¹äº‘ â†’ ç¨€ç–å¼ é‡
    2. ç½‘ç»œæ¨ç† â†’ ä¸‰ä¸ªè¾“å‡º
    3. è¿”å›é¢„æµ‹ç»“æœ
    
    è¾“å…¥: dataå­—å…¸ï¼ŒåŒ…å«åæ ‡ã€é¢œè‰²ã€æ ‡ç­¾ç­‰
    è¾“å‡º: (è¯­ä¹‰é¢„æµ‹, æ ‡å‡†å®ä¾‹åç§», å±‚æ¬¡å®ä¾‹åç§»)
    """
    # åˆ›å»ºç¨€ç–å¼ é‡
    sinput = ME.SparseTensor(
        features=data['colors'],           # RGBç‰¹å¾
        coordinates=data['quantized'],     # ä½“ç´ åŒ–åæ ‡
        device=self.device
    )
    
    # ç½‘ç»œå‰å‘ä¼ æ’­
    soutput, ins1, ins2 = self.network(sinput)
    
    # è¿”å›ä¸‰ä¸ªè¾“å‡º:
    # soutput: è¯­ä¹‰åˆ†å‰²ç»“æœ (6ç±»)
    # ins1: æ ‡å‡†å®ä¾‹åç§»å‘é‡ (3D)
    # ins2: å±‚æ¬¡å®ä¾‹åç§»å‘é‡ (3D)
    return soutput, ins1, ins2
```

### 3. æŸå¤±å‡½æ•°

```python
def getLoss(self, data, soutput, ins1, ins2):
    """
    æŸå¤±å‡½æ•°è®¡ç®—:
    
    æ€»æŸå¤± = è¯­ä¹‰æŸå¤± + æ ‡å‡†å®ä¾‹æŸå¤± + å±‚æ¬¡å®ä¾‹æŸå¤±
    
    1. è¯­ä¹‰æŸå¤±: CrossEntropyLoss
       - 6ç±»åˆ†ç±»ä»»åŠ¡
       - å¿½ç•¥voidç±»åˆ«(index=0)
    
    2. æ ‡å‡†å®ä¾‹æŸå¤±: IoU LovÃ¡sz Loss
       - ä»…å¯¹thingsç±»åˆ«(fruit, trunk)è®¡ç®—
       - åŸºäºåç§»å‘é‡é¢„æµ‹
    
    3. å±‚æ¬¡å®ä¾‹æŸå¤±: IoU LovÃ¡sz Loss
       - å¯¹treeå®ä¾‹è®¡ç®—
       - ä½¿ç”¨å±‚æ¬¡æ ‡ç­¾(semantic_h, instance_h)
    """
    
    # è¯­ä¹‰åˆ†å‰²æŸå¤±
    sem_loss = self.ce(soutput.F, sem_labels.long())
    
    # æ ‡å‡†å®ä¾‹æŸå¤± (fruit + trunk)
    ins1_loss = self.lovasz(
        ins1.F[things_mask],      # åç§»é¢„æµ‹
        coords[things_mask],       # ç‚¹åæ ‡
        instance[things_mask]      # å®ä¾‹æ ‡ç­¾
    )
    
    # å±‚æ¬¡å®ä¾‹æŸå¤± (tree)
    ins2_loss = self.lovasz(
        ins2.F[things_h_mask],
        coords[things_h_mask],
        instance_h[things_h_mask]
    )
    
    return sem_loss + ins1_loss + ins2_loss, sem_loss, ins1_loss, ins2_loss
```

### 4. MinkUNetæ¶æ„ (`models/minkunet_full.py`)

**ç½‘ç»œç»“æ„æ¦‚è§ˆ:**

```
è¾“å…¥ â†’ ç¼–ç å™¨ â†’ ä¸‰ä¸ªå¹¶è¡Œè§£ç å™¨ â†’ ä¸‰ä¸ªè¾“å‡º
                â”œâ”€â”€ è¯­ä¹‰è§£ç å™¨ â†’ è¯­ä¹‰é¢„æµ‹ (6ç±»)
                â”œâ”€â”€ å±‚æ¬¡å®ä¾‹è§£ç å™¨ â†’ åç§»å‘é‡ (3D) â†’ æ ‘å®ä¾‹
                â””â”€â”€ æ ‡å‡†å®ä¾‹è§£ç å™¨ â†’ åç§»å‘é‡ (3D) â†’ æœå®/æ ‘å¹²å®ä¾‹
```

**ç¼–ç å™¨ç»“æ„:**

```python
# ç¼–ç å™¨ - é€æ­¥ä¸‹é‡‡æ ·
conv0 â†’ block1 (stride=2)  # è¾“å‡º: out_b1p2, æ­¥å¹…2
      â†’ block2 (stride=2)  # è¾“å‡º: out_b2p4, æ­¥å¹…4  
      â†’ block3 (stride=2)  # è¾“å‡º: out_b3p8, æ­¥å¹…8
      â†’ block4 (stride=2)  # è¾“å‡º: out_encoder, æ­¥å¹…16
```

**è¯­ä¹‰è§£ç å™¨ç»“æ„:**

```python
# è¯­ä¹‰è§£ç å™¨ - é€æ­¥ä¸Šé‡‡æ · + ç¼–ç å™¨è·³è·ƒè¿æ¥
convtr4 â†’ cat(out_skip_sem1, out_b3p8) â†’ block5  # æ­¥å¹…8
convtr5 â†’ cat(out_skip_sem2, out_b2p4) â†’ block6  # æ­¥å¹…4
convtr6 â†’ cat(out_skip_sem3, out_b1p2) â†’ block7  # æ­¥å¹…2
convtr7 â†’ cat(out_skip_sem4, out_p1)   â†’ block8  # æ­¥å¹…1
final â†’ 6ç±»é¢„æµ‹
```

**å±‚æ¬¡å®ä¾‹è§£ç å™¨ (ins2) - è®ºæ–‡æ ¸å¿ƒåˆ›æ–°:**

```python
# å±‚æ¬¡å®ä¾‹è§£ç å™¨ - ç¼–ç å™¨ + è¯­ä¹‰è§£ç å™¨çš„è·³è·ƒè¿æ¥
convtr4_ins2 â†’ cat(out_ins2, out_b3p8, out_skip_sem1) â†’ block5_ins2
convtr5_ins2 â†’ cat(out_ins2, out_b2p4, out_skip_sem2) â†’ block6_ins2
convtr6_ins2 â†’ cat(out_ins2, out_b1p2, out_skip_sem3) â†’ block7_ins2
convtr7_ins2 â†’ cat(out_ins2, out_p1, out_skip_sem4)   â†’ block8_ins2
final_ins2 â†’ 3Dåç§»å‘é‡ â†’ tanhæ¿€æ´»
```

**æ ‡å‡†å®ä¾‹è§£ç å™¨ (ins1) - è®ºæ–‡æ ¸å¿ƒåˆ›æ–°:**

```python
# æ ‡å‡†å®ä¾‹è§£ç å™¨ - ç¼–ç å™¨ + å±‚æ¬¡å®ä¾‹è§£ç å™¨çš„è·³è·ƒè¿æ¥
convtr4_ins1 â†’ cat(out_ins1, out_b3p8, out_skip_ins1) â†’ block5_ins1
convtr5_ins1 â†’ cat(out_ins1, out_b2p4, out_skip_ins2) â†’ block6_ins1
convtr6_ins1 â†’ cat(out_ins1, out_b1p2, out_skip_ins3) â†’ block7_ins1
convtr7_ins1 â†’ cat(out_ins1, out_p1, out_skip_ins4)   â†’ block8_ins1
final_ins1 â†’ 3Dåç§»å‘é‡ â†’ tanhæ¿€æ´»
```

**è·³è·ƒè¿æ¥å¯è§†åŒ–:**

```
           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
           â”‚                    ç¼–ç å™¨ç‰¹å¾                            â”‚
           â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”˜
                  â”‚              â”‚               â”‚               â”‚
                  â–¼              â–¼               â–¼               â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚                   è¯­ä¹‰è§£ç å™¨                                 â”‚
        â”‚   block5 â”€â†’ block6 â”€â†’ block7 â”€â†’ block8 â”€â†’ è¯­ä¹‰é¢„æµ‹         â”‚
        â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚              â”‚               â”‚               â”‚
               â–¼              â–¼               â–¼               â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚                 å±‚æ¬¡å®ä¾‹è§£ç å™¨ (ins2)                        â”‚
        â”‚   block5 â”€â†’ block6 â”€â†’ block7 â”€â†’ block8 â”€â†’ æ ‘åç§»            â”‚
        â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚              â”‚               â”‚               â”‚
               â–¼              â–¼               â–¼               â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚                 æ ‡å‡†å®ä¾‹è§£ç å™¨ (ins1)                        â”‚
        â”‚   block5 â”€â†’ block6 â”€â†’ block7 â”€â†’ block8 â”€â†’ æœå®/æ ‘å¹²åç§»     â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“Š åå¤„ç†ä¸è¯„ä¼°

### 1. å®ä¾‹èšç±»åå¤„ç†

```python
def post_processing(self, soutput, ins1, ins2, data):
    """
    åå¤„ç†æµç¨‹:
    
    1. è·å–è¯­ä¹‰é¢„æµ‹ (argmax)
    2. è®¡ç®—å®ä¾‹ä¸­å¿ƒé¢„æµ‹
    3. HDBSCANèšç±»ç”Ÿæˆå®ä¾‹åˆ†å‰²
    
    å…³é”®å‚æ•°:
    - min_n_points_fruit: 60 (æœå®æœ€å°ç‚¹æ•°)
    - min_n_points_trunk: 250 (æ ‘å¹²æœ€å°ç‚¹æ•°)
    - min_n_points_tree: 1000 (æ ‘æœ¨æœ€å°ç‚¹æ•°)
    """
    
    # è¯­ä¹‰é¢„æµ‹
    sem = soutput.F.argmax(dim=1)
    
    # å®ä¾‹ä¸­å¿ƒé¢„æµ‹ = ç‚¹åæ ‡ + åç§»å‘é‡
    ins1_centers = coords + ins1.F  # æ ‡å‡†å®ä¾‹ä¸­å¿ƒ
    ins2_centers = coords + ins2.F  # å±‚æ¬¡å®ä¾‹ä¸­å¿ƒ
    
    # HDBSCANèšç±»
    for cls_id in [3, 4]:  # fruit, trunk
        mask = (sem == cls_id)
        if mask.sum() > min_points:
            clusterer = hdbscan.HDBSCAN(min_cluster_size=min_points)
            clusters = clusterer.fit_predict(ins1_centers[mask])
            # åˆ†é…å®ä¾‹ID
```

### 2. è¯„ä¼°æŒ‡æ ‡

```python
class Metrics:
    """
    è¯„ä¼°æŒ‡æ ‡ç±»ï¼Œè®¡ç®—:
    
    1. mIoU (Mean Intersection over Union)
       - è¯­ä¹‰åˆ†å‰²è¯„ä¼°
       - å¿½ç•¥voidç±»åˆ«å5ç±»çš„å¹³å‡IoU
    
    2. PQ (Panoptic Quality)
       - æ ‡å‡†å…¨æ™¯åˆ†å‰²è¯„ä¼°
       - åˆ†åˆ«è¯„ä¼°thingså’Œstuffç±»åˆ«
       - PQ = SQ Ã— RQ (åˆ†å‰²è´¨é‡ Ã— è¯†åˆ«è´¨é‡)
    
    3. PQ_h (Hierarchical Panoptic Quality)
       - å±‚æ¬¡å…¨æ™¯åˆ†å‰²è¯„ä¼°
       - è¯„ä¼°æ ‘çº§åˆ«çš„å®ä¾‹åˆ†å‰²
    """
```

**æŒ‡æ ‡è®¡ç®—:**

| æŒ‡æ ‡ | è®¡ç®—æ–¹å¼ | è¯„ä¼°å¯¹è±¡ |
|------|---------|---------|
| mIoU | å„ç±»IoUçš„å¹³å‡å€¼ | è¯­ä¹‰åˆ†å‰² |
| PQ | SQ Ã— RQ | æ ‡å‡†å…¨æ™¯åˆ†å‰² |
| PQ_h | SQ Ã— RQ (æ ‘çº§åˆ«) | å±‚æ¬¡å…¨æ™¯åˆ†å‰² |

---

## ğŸš€ è¿è¡ŒæŒ‡å—

### 1. è®­ç»ƒæ¨¡å‹

```bash
# ä½¿ç”¨é»˜è®¤é…ç½®è®­ç»ƒ
python train.py

# ä½¿ç”¨ç‰¹å®šé…ç½®æ–‡ä»¶è®­ç»ƒ
python train.py --config config/config_full.yaml
```

**è®­ç»ƒè„šæœ¬å…³é”®å‚æ•°:**

```python
# train.py æ ¸å¿ƒä»£ç 
trainer = Trainer(
    max_epochs=cfg['train']['max_epoch'],  # æœ€å¤§è®­ç»ƒè½®æ•°
    accelerator='gpu',                      # ä½¿ç”¨GPU
    devices=cfg['train']['n_gpus'],         # GPUæ•°é‡
    logger=tb_logger,                       # TensorBoardæ—¥å¿—
    callbacks=[                             # å›è°ƒå‡½æ•°
        # å¤šä¸ªModelCheckpointï¼Œç›‘æ§ä¸åŒæŒ‡æ ‡
        checkpoint_miou,     # ç›‘æ§mIoU
        checkpoint_mpq,      # ç›‘æ§mPQ
        checkpoint_pqh,      # ç›‘æ§PQ_h
        checkpoint_ins1,     # ç›‘æ§ins1_loss
        checkpoint_ins2,     # ç›‘æ§ins2_loss
    ]
)
```

**è®­ç»ƒè¾“å‡º:**
- æ¨¡å‹æ£€æŸ¥ç‚¹: `lightning_logs/version_X/checkpoints/`
- TensorBoardæ—¥å¿—: `lightning_logs/version_X/`
- æœ€ä½³æ¨¡å‹æŒ‰ä¸åŒæŒ‡æ ‡ä¿å­˜

### 2. æµ‹è¯•æ¨¡å‹

```bash
# æµ‹è¯•è®­ç»ƒå¥½çš„æ¨¡å‹
python test.py --checkpoint path/to/checkpoint.ckpt
```

### 3. æŸ¥çœ‹è®­ç»ƒæ—¥å¿—

```bash
# å¯åŠ¨TensorBoard
tensorboard --logdir lightning_logs/
```

### 4. Dockerè¿è¡Œ

```bash
# æ„å»ºDockeré•œåƒ
docker-compose build

# å¯åŠ¨å®¹å™¨
docker-compose up
```

---

## ğŸ“ˆ æŸå¤±å‡½æ•°è¯¦è§£

### 1. è¯­ä¹‰åˆ†å‰²æŸå¤± (CrossEntropyLoss)

```python
# æ ‡å‡†äº¤å‰ç†µæŸå¤±
ce_loss = CrossEntropyLoss(ignore_index=0)  # å¿½ç•¥voidç±»åˆ«

# è®¡ç®—
sem_loss = ce_loss(predictions, labels)
```

### 2. å®ä¾‹åˆ†å‰²æŸå¤± (IoU LovÃ¡sz Loss)

```python
class IoULovaszLoss:
    """
    åŸºäºLovÃ¡szæ‰©å±•çš„IoUæŸå¤±å‡½æ•°
    
    åŸç†:
    1. ä»åç§»å‘é‡è®¡ç®—è½¯æ©ç 
    2. åº”ç”¨LovÃ¡szæ¢¯åº¦è¿›è¡Œæ’åº
    3. è®¡ç®—IoUæŸå¤±
    
    ä¼˜åŠ¿:
    - ç›´æ¥ä¼˜åŒ–IoUæŒ‡æ ‡
    - å¯¹ä¸å¹³è¡¡æ•°æ®æ›´é²æ£’
    """
    
    def forward(self, offsets, coordinates, instance_labels):
        # è®¡ç®—é¢„æµ‹ä¸­å¿ƒ
        pred_centers = coordinates + offsets
        
        # ä¸ºæ¯ä¸ªå®ä¾‹è®¡ç®—è½¯æ©ç 
        for instance_id in unique_instances:
            # è·å–å®ä¾‹è´¨å¿ƒ
            centroid = mean(pred_centers[mask])
            
            # è®¡ç®—åˆ°è´¨å¿ƒçš„è·ç¦» â†’ è½¯æ©ç 
            distances = ||pred_centers - centroid||
            soft_mask = 1 - sigmoid(distances)
            
            # LovÃ¡szæŸå¤±
            loss += lovasz_hinge(soft_mask, ground_truth_mask)
        
        return loss
```

---

## ğŸ” å…³é”®ä»£ç ç‰‡æ®µè§£æ

### 1. ä½“ç´ åŒ–å¤„ç†

```python
# å°†è¿ç»­åæ ‡é‡åŒ–ä¸ºç¦»æ•£ä½“ç´ 
voxel_resolution = 0.003  # 3mmåˆ†è¾¨ç‡

# é‡åŒ–åæ ‡
quantized = torch.floor(coords / voxel_resolution).int()

# åˆ›å»ºç¨€ç–å¼ é‡
sinput = ME.SparseTensor(
    features=colors,
    coordinates=quantized,
    device=device
)
```

### 2. ç¨€ç–å·ç§¯æ“ä½œ

```python
# MinkowskiEngineç¨€ç–å·ç§¯
conv = ME.MinkowskiConvolution(
    in_channels=32,
    out_channels=64,
    kernel_size=3,
    stride=2,
    dimension=3  # 3Dç©ºé—´
)

# è½¬ç½®å·ç§¯ï¼ˆä¸Šé‡‡æ ·ï¼‰
convtr = ME.MinkowskiConvolutionTranspose(
    in_channels=64,
    out_channels=32,
    kernel_size=2,
    stride=2,
    dimension=3
)

# ç‰¹å¾æ‹¼æ¥
out = ME.cat(feature1, feature2, feature3)
```

### 3. HDBSCANèšç±»

```python
import hdbscan

# åˆ›å»ºèšç±»å™¨
clusterer = hdbscan.HDBSCAN(
    min_cluster_size=60,     # æœ€å°èšç±»å¤§å°
    cluster_selection_epsilon=0.1
)

# æ‰§è¡Œèšç±»
cluster_labels = clusterer.fit_predict(predicted_centers)

# -1 è¡¨ç¤ºå™ªå£°ç‚¹
valid_clusters = cluster_labels[cluster_labels >= 0]
```

---

## ğŸ¯ è°ƒå‚å»ºè®®

### 1. å­¦ä¹ ç‡è°ƒæ•´

```yaml
train:
  lr: 0.005  # é»˜è®¤å€¼
  # å»ºè®®èŒƒå›´: 0.001 - 0.01
  # å¦‚æœlosséœ‡è¡ï¼Œå°è¯•å‡å°
  # å¦‚æœæ”¶æ•›å¤ªæ…¢ï¼Œå°è¯•å¢å¤§
```

### 2. ä½“ç´ åˆ†è¾¨ç‡

```yaml
train:
  voxel_resolution: 0.003  # 3mm
  # æ›´å°çš„å€¼ â†’ æ›´å¤šç»†èŠ‚ï¼Œæ›´å¤§å†…å­˜æ¶ˆè€—
  # æ›´å¤§çš„å€¼ â†’ æ›´å¿«å¤„ç†ï¼Œå¯èƒ½ä¸¢å¤±ç»†èŠ‚
```

### 3. æ•°æ®å¢å¼ºå¼ºåº¦

```yaml
transform:
  # å‡ ä½•å¢å¼º
  max_rotation_angle_degree_z: 180  # Zè½´æ—‹è½¬èŒƒå›´
  max_shear: 0.2                    # å‰ªåˆ‡å¼ºåº¦
  
  # é¢œè‰²å¢å¼º
  max_brightness: 0.2               # äº®åº¦å˜åŒ–
  max_hue: 0.15                     # è‰²è°ƒå˜åŒ–
```

### 4. å®ä¾‹åå¤„ç†é˜ˆå€¼

```yaml
val:
  min_n_points_fruit: 60    # æœå®æœ€å°ç‚¹æ•°
  min_n_points_trunk: 250   # æ ‘å¹²æœ€å°ç‚¹æ•°
  min_n_points_tree: 1000   # æ ‘æœ¨æœ€å°ç‚¹æ•°
  # å¢å¤§ â†’ æ›´å°‘ä½†æ›´å¯é çš„å®ä¾‹
  # å‡å° â†’ æ›´å¤šä½†å¯èƒ½æœ‰å™ªå£°çš„å®ä¾‹
```

---

## ğŸ“ ä»£ç æ‰©å±•æŒ‡å—

### 1. æ·»åŠ æ–°çš„è¯­ä¹‰ç±»åˆ«

```python
# 1. ä¿®æ”¹é…ç½®æ–‡ä»¶
tasks:
  semantic_segmentation:
    n_classes: 7  # å¢åŠ ä¸€ç±»

# 2. ä¿®æ”¹è¯„ä¼°ä»£ç  (utils/evaluation.py)
STUFF_IDS = [1, 2, 5, 6]  # æ·»åŠ æ–°çš„stuffç±»åˆ«
# æˆ–
THINGS_IDS = [3, 4, 6]    # æ·»åŠ æ–°çš„thingsç±»åˆ«

# 3. æ›´æ–°æ•°æ®é›†æ ‡ç­¾
```

### 2. ä½¿ç”¨è‡ªå®šä¹‰æ•°æ®é›†

```python
# ç¡®ä¿PLYæ–‡ä»¶åŒ…å«ä»¥ä¸‹å­—æ®µ:
# - x, y, z: ç‚¹åæ ‡
# - red, green, blue: RGBé¢œè‰² (0-255)
# - semantic: è¯­ä¹‰æ ‡ç­¾
# - instance: å®ä¾‹ID
# - semantic_h: å±‚æ¬¡è¯­ä¹‰æ ‡ç­¾
# - instance_h: å±‚æ¬¡å®ä¾‹ID

# æ•°æ®é›†ç›®å½•ç»“æ„:
# data/your_dataset/
#   â”œâ”€â”€ train/
#   â”‚   â”œâ”€â”€ scene1.ply
#   â”‚   â””â”€â”€ scene2.ply
#   â”œâ”€â”€ val/
#   â”‚   â””â”€â”€ scene3.ply
#   â””â”€â”€ test/
#       â””â”€â”€ scene4.ply
```

### 3. ä¿®æ”¹ç½‘ç»œæ¶æ„

```python
# åœ¨ models/ ç›®å½•ä¸‹åˆ›å»ºæ–°çš„ç½‘ç»œæ–‡ä»¶
# ç»§æ‰¿ MinkUNetBase ç±»
class CustomMinkUNet(MinkUNetBase):
    BLOCK = BasicBlock
    LAYERS = (2, 2, 2, 2, 2, 2, 2, 2)  # è‡ªå®šä¹‰å±‚æ•°
    # ...
```

---

## ğŸ› å¸¸è§é—®é¢˜æ’æŸ¥

### 1. CUDAå†…å­˜ä¸è¶³

```bash
# é”™è¯¯: CUDA out of memory
# è§£å†³æ–¹æ¡ˆ:
# 1. å¢å¤§ä½“ç´ åˆ†è¾¨ç‡
voxel_resolution: 0.005  # ä»0.003å¢å¤§åˆ°0.005

# 2. å‡å°‘æ•°æ®å¢å¼ºçš„ä¸‹é‡‡æ ·
min_downsample: 0.8  # ä»0.6å¢å¤§åˆ°0.8
```

### 2. MinkowskiEngineå®‰è£…å¤±è´¥

```bash
# ç¡®ä¿å®‰è£…äº†æ­£ç¡®ç‰ˆæœ¬çš„ä¾èµ–
pip install numpy==1.24.2
pip install setuptools==60.0

# ä»æºç å®‰è£…
git clone https://github.com/NVIDIA/MinkowskiEngine.git
cd MinkowskiEngine
python setup.py install
```

### 3. è®­ç»ƒlossä¸ä¸‹é™

```python
# æ£€æŸ¥å­¦ä¹ ç‡æ˜¯å¦åˆé€‚
lr: 0.001  # å°è¯•å‡å°

# æ£€æŸ¥æ•°æ®å¢å¼ºæ˜¯å¦è¿‡å¼º
max_rotation_angle_degree_z: 90  # å‡å°æ—‹è½¬èŒƒå›´

# æ£€æŸ¥ä½“ç´ åˆ†è¾¨ç‡
voxel_resolution: 0.005  # å°è¯•å¢å¤§
```

---

## ğŸ“š å‚è€ƒèµ„æ–™

- **MinkowskiEngineæ–‡æ¡£**: https://nvidia.github.io/MinkowskiEngine/
- **PyTorch Lightningæ–‡æ¡£**: https://lightning.ai/docs/pytorch/stable/
- **HDBSCANæ–‡æ¡£**: https://hdbscan.readthedocs.io/
- **Open3Dæ–‡æ¡£**: http://www.open3d.org/docs/

---

*æœ¬æ–‡æ¡£ç”±ä»£ç åˆ†æè‡ªåŠ¨ç”Ÿæˆï¼Œå¦‚æœ‰ç–‘é—®è¯·å‚è€ƒæºä»£ç æˆ–è”ç³»ä½œè€…ã€‚*



# HAPT3D

### Train
Run `python train.py --config config/config_full.yaml`. Remember to change the path to the dataset folder in the config file and in the `train.py` file.

### Testing
Run `python test.py -w <file>`. Remember to change the path to the dataset folder in the config file and in the `test.py` file. If you want to test on the validation set, uncomment lines 41-44 in `test.py`.

### Installation
After struggling a bit to install MinkowskiEngine, the procedure below is the one that worked out on my machine (operations to be done in that specific order):

```
    conda create --name hapt3d python=3.9
    conda activate hapt3d
    pip install torch==1.12.1+cu113 --extra-index-url https://download.pytorch.org/whl/cu113 --no-cache-dir
    pip install numpy==1.24.2
    pip install setuptools==60.0
    pip install pykeops --no-cache-di
    pip3 install -U git+https://github.com/NVIDIA/MinkowskiEngine -v --no-deps
    pip install pytorch-lightning==1.9.0 --no-deps
    pip install fsspec
    pip install lightning-utilities
    pip install tqdm
    pip install pyyaml
    pip install torchmetrics==1.4.1
    pip install ipdb
    pip install open3d
    pip install tensorboard
    pip install torchmetrics
    pip install hdbscan
    pip install distinctipy
    pip install optuna==3.6.1
    pip install optuna-integration
```

Good luck :)

### Docker
Alternatively, you could simply use docker. Build it first via `make build`, then you can train via doing `make train` and test with `make test CHECKPOINT=<file>`.

